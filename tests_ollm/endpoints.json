{
  "dev": [
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "codellama-7b-instruct-fp16"
    },
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "codellama-13b-instruct-fp16"
    },
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "codellama-34b-instruct-int4"
    },
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "codellama-34b-instruct-fp16"
    },
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "llama-2-13b-chat-fp16"
    },
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "llama-2-70b-chat-int4"
    },
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "llama-2-70b-chat-fp16"      
    },
    {
      "url": "https://text.customer-endpoints.nimbus.octoml.ai",
      "model": "mistral-7b-instruct-fp16"
    }      

  ],

  "prod": [
    {
      "url": "https://text.octoai.run",
      "model": "codellama-7b-instruct-fp16"
    },
    {
      "url": "https://text.octoai.run",
      "model": "codellama-13b-instruct-fp16"
    },
    {
      "url": "https://text.octoai.run",
      "model": "codellama-34b-instruct-int4"
    },
    {
      "url": "https://text.octoai.run",
      "model": "codellama-34b-instruct-fp16"
    },
    {
      "url": "https://text.octoai.run",
      "model": "llama-2-13b-chat-fp16"
    },
    {
      "url": "https://text.octoai.run",
      "model": "llama-2-70b-chat-int4"
    },
    {
      "url": "https://text.octoai.run",
      "model": "llama-2-70b-chat-fp16"      
    },
    {
      "url": "https://text.octoai.run",
      "model": "mistral-7b-instruct-fp16"
    }      
  ]
}
